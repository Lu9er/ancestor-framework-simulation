# Multi-Agent Trust Simulation with Ancestor Verifier

## üéØ Overview

This repository contains a multi-agent simulation system that demonstrates how a deterministic trust-scoring engine (called "Ancestor") influences citation behavior in cooperative systems. The simulation is designed for academic and research review purposes, using real, verifiable, and auditable data sources.

## üèóÔ∏è System Architecture

The simulation consists of three primary agents:

1. **Claimant Agent**: Randomly selects citations from the dataset and makes factual claims
2. **Ancestor Verifier**: Scores the trustworthiness of citations using rule-based heuristics
3. **Consumer Agent**: Accepts or rejects claims based on the trust score threshold

## üìÑ Input Data: `public_citation_sources.csv`

The simulation uses a real dataset of 100 verified citations with the following schema:

- **Category**: Source type (e.g., "Academic Research", "News Outlet", "Gov Report")
- **URL**: Full citation URL
- **Domain**: Domain name (e.g., "who.int", "bbc.com", "harvard.edu")
- **Age**: Original data shows "Ongoing" for all entries
- **Trust_Description**: Short justification of source trustworthiness

### ‚ö†Ô∏è Critical Note on Age Data Handling

**Original Dataset Issue**: All entries in `public_citation_sources.csv` contain "Ongoing" in the Age field, which would make age-based scoring impossible and unrealistic for simulation purposes.

**Solution Implemented**: To create a meaningful simulation that demonstrates the Ancestor scoring system's age-based penalties, the simulation generates realistic age values during runtime:

```python
# In ClaimantAgent.make_claim() method
age_days = random.randint(0, 365)  # Random age between 0-365 days
```

**Why This Approach**:
1. **Demonstrates Age Scoring Logic**: Shows how the Ancestor system would handle sources of varying ages
2. **Creates Realistic Scenarios**: Simulates real-world conditions where sources have different ages
3. **Maintains Reproducibility**: Uses fixed random seed (42) for consistent results
4. **Preserves Original Data**: No modification to the source CSV file

**Age Range Justification**:
- **0-365 days**: Represents sources from "today" to "one year old"
- **Realistic Distribution**: Covers fresh sources to moderately aged content
- **Scoring Impact**: Creates meaningful variance in trust scores (newer sources score higher)

## üß† Ancestor Trust Scoring Algorithm

**[Patent Pending - Proprietary Algorithm]**

The Ancestor Verifier implements a deterministic scoring system that evaluates multiple trust factors:

### Key Evaluation Factors

1. **Source Recency**: More recent sources receive higher trust scores
2. **Domain Authority**: Trusted domains (.edu, .gov, .org, .int) are scored favorably
3. **Content Credibility**: Sources are evaluated for bias and reliability indicators
4. **Source Type**: Academic, government, and verified sources score higher

### Scoring Characteristics

- **Deterministic**: Same inputs always produce same outputs
- **Transparent**: All scoring decisions are auditable
- **Range**: Scores from 0 to 100
- **Threshold-based**: Configurable acceptance thresholds (default: 60)

### Implementation Note

The specific scoring formulas and weights are proprietary and patent-pending. The simulation demonstrates the framework's effectiveness without revealing the exact algorithm implementation.

## üìä Consumer Decision Logic

The Consumer Agent uses a threshold-based decision:

- **Acceptance Threshold**: 60.0 (configurable)
- **Score ‚â• Threshold**: Claim accepted
- **Score < Threshold**: Claim rejected

## üîÑ Simulation Process

### Episode Flow (100 iterations)

1. **Claimant Phase**:
   - Randomly selects one row from `public_citation_sources.csv`
   - Generates random age (0-365 days)
   - Creates claim with citation data

2. **Verification Phase**:
   - Ancestor applies scoring algorithm
   - Calculates final trust score

3. **Consumer Phase**:
   - Evaluates trust score against threshold
   - Makes accept/reject decision

4. **Logging Phase**:
   - Records episode data to results

### Reproducibility

- **Fixed Random Seed**: `random.seed(42)` and `np.random.seed(42)`
- **Deterministic Scoring**: Rule-based heuristics with no randomness
- **Consistent Dataset**: Same CSV file for all runs

## üìà Output Files

### `results.csv`
Complete simulation log with columns:
- `episode`: Episode number (1-100)
- `url`: Selected citation URL
- `domain`: Domain name
- `category`: Source category
- `age_days`: Generated age in days
- `score`: Calculated trust score
- `accepted`: Decision (1=accepted, 0=rejected)

### `trust_plot.png`
Matplotlib visualization containing:
- **Top Panel**: Trust scores across 100 episodes with acceptance threshold line
- **Bottom Panel**: Accept/reject decisions as binary plot

### `build_log.txt`
Complete execution audit trail documenting every step taken by the coding agent.

## üöÄ Running the Simulation

### Prerequisites
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install pandas matplotlib numpy
```

### Execution
```bash
python main.py
```

### Expected Output
```
MULTI-AGENT TRUST SIMULATION WITH ANCESTOR VERIFIER
============================================================
[STEP 1] Loaded citation data from public_citation_sources.csv - 100 entries found
[STEP 2] Defined Ancestor scoring function with penalties for age, domain type, and bias keywords
[STEP 3] Starting 100-episode simulation with Claimant, Verifier, and Consumer agents
[STEP 4] Completed 100 episodes with trust scoring and decision logging
...

=== SIMULATION SUMMARY ===
Total Episodes: 100
Claims Accepted: X (X.X%)
Claims Rejected: X (X.X%)
Average Trust Score: XX.XX
Score Range: XX.XX - XX.XX
```

## üìä Expected Results Analysis

Based on the scoring algorithm and dataset characteristics:

### High Acceptance Rate Expected
Most citations should be accepted because:
1. **Quality Dataset**: All sources are pre-verified as trustworthy
2. **Trusted Domains**: Many `.edu`, `.gov`, `.org` domains (no penalties)
3. **Conservative Age Range**: 0-365 days creates minimal age penalties
4. **No Bias Content**: Trust descriptions are positive, avoiding bias penalties

### Score Distribution
- **High Scores (90-100)**: `.edu/.gov/.org` domains with low age
- **Medium Scores (85-95)**: `.com` domains with academic content
- **Lower Scores (60-85)**: Older `.com` domains with penalties

## üîç Code Structure

### Main Classes

#### `AncestorVerifier`
Implements the deterministic trust scoring engine with configurable penalties.

#### `ClaimantAgent`
Handles random citation selection and realistic age generation.

#### `ConsumerAgent`
Makes binary accept/reject decisions based on trust threshold.

#### `TrustSimulation`
Orchestrates the complete simulation workflow and output generation.

## üéØ Research Applications

This simulation enables researchers to:

1. **Study Trust Dynamics**: How deterministic scoring affects agent behavior
2. **Analyze Decision Patterns**: Impact of different threshold values
3. **Evaluate Scoring Algorithms**: Test modifications to Ancestor's rules
4. **Compare Trust Systems**: Benchmark against other verification approaches

## ‚ö†Ô∏è Important Notes

### Data Authenticity
- **Real Sources**: All URLs and domains from actual reputable sources
- **No Synthetic Data**: No placeholder or fake citations used
- **Verifiable Results**: All claims can be traced to original dataset

### Age Data Methodology
- **Generated Ages**: Realistic 0-365 day range for meaningful scoring
- **Fixed Seed**: Reproducible results across runs
- **Documented Approach**: Clear explanation of why generation was necessary

### Limitations
- **Simplified Consumer**: Binary threshold decision (could be enhanced)
- **Static Scoring**: No learning or adaptation in Ancestor
- **Limited Age Range**: Real-world sources might be much older

## üìù Files Overview

- `main.py`: Complete simulation implementation
- `public_citation_sources.csv`: Input dataset (100 verified citations)
- `results.csv`: Simulation episode results
- `trust_plot.png`: Visualization of trust scores and decisions
- `build_log.txt`: Agent execution audit trail
- `README.md`: This documentation file

## ü§ù Academic Use

This simulation is designed for:
- **Research Publications**: Demonstrating multi-agent trust systems
- **Educational Purposes**: Teaching trust and verification concepts
- **Algorithm Development**: Testing trust scoring approaches
- **Reproducible Science**: All data and methods are transparent

For questions about methodology or implementation details, refer to the source code comments and build log for complete transparency.